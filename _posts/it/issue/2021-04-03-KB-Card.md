---
layout: post
title: "Project KBCard- Issue"
author: "Bys"
category: issue
date: 2021-04-03 01:00:00
tags: troubleshooting issue
---

#### **- Secondary IP & DNS 이슈**

EKS Pod에서 Secondary IP를 사용하면서 DNS Lookup이 되지 않은 현상  
Pod의 /etc/resolv.conf 에서 172.20.0.10 의 nameserver 셋팅이 되어 있었음  
```bash
caused by: Error: RequestError: send request failed 
caused by: Post  dial tcp: i/o timeout
```

위 와 같은 오류가 발생하였으며 bootstarp.sh 파일을 살펴보면 아래의 내용이 존재한다.  
DNS_CLUSTER_IP를 kube-dns 서비스의 CLUSTER-IP(kubectl get svc kube-dns -n kube-system / 172.16.0.10)로 값을 넘겨주는 셋팅을 한다.  
해당 설정을 마치면 Pod의 nameserver가 core-dns의 nameserver로 정상 셋팅이 된다.  

```bash
while [[ $# -gt 0 ]]; do
    key="$1"
    case $key in
        -h|--help)
            print_help
            exit 1
            ;;
        --use-max-pods)
            USE_MAX_PODS="$2"
            shift
            shift
            ;;
        --b64-cluster-ca)
            B64_CLUSTER_CA=$2
            shift
            shift
            ;;
        --apiserver-endpoint)
            APISERVER_ENDPOINT=$2
            shift
            shift
            ;;
        --kubelet-extra-args)
            KUBELET_EXTRA_ARGS=$2
            shift
            shift
            ;;
        --enable-docker-bridge)
            ENABLE_DOCKER_BRIDGE=$2
            shift
            shift
            ;;
        --aws-api-retry-attempts)
            API_RETRY_ATTEMPTS=$2
            shift
            shift
            ;;
        --docker-config-json)
            DOCKER_CONFIG_JSON=$2
            shift
            shift
            ;;
        --pause-container-account)
            PAUSE_CONTAINER_ACCOUNT=$2
            shift
            shift
            ;;
        --pause-container-version)
            PAUSE_CONTAINER_VERSION=$2
            shift
            shift
            ;;
        --dns-cluster-ip)
            DNS_CLUSTER_IP=$2
            shift
            shift
            ;;
        *)    # unknown option
            POSITIONAL+=("$1") # save it in an array for later
            shift # past argument
            ;;
    esac
done

set +u
set -- "${POSITIONAL[@]}" # restore positional parameters
CLUSTER_NAME="$1"
set -u

USE_MAX_PODS="${USE_MAX_PODS:-true}"
B64_CLUSTER_CA="${B64_CLUSTER_CA:-}"
APISERVER_ENDPOINT="${APISERVER_ENDPOINT:-}"
SERVICE_IPV4_CIDR="${SERVICE_IPV4_CIDR:-}"
DNS_CLUSTER_IP="${DNS_CLUSTER_IP:-}"
KUBELET_EXTRA_ARGS="${KUBELET_EXTRA_ARGS:-}"
ENABLE_DOCKER_BRIDGE="${ENABLE_DOCKER_BRIDGE:-false}"
API_RETRY_ATTEMPTS="${API_RETRY_ATTEMPTS:-3}"
DOCKER_CONFIG_JSON="${DOCKER_CONFIG_JSON:-}"
PAUSE_CONTAINER_VERSION="${PAUSE_CONTAINER_VERSION:-3.1-eksbuild.1}"

......

if [[ -z "${DNS_CLUSTER_IP}" ]]; then
  if [[ ! -z "${SERVICE_IPV4_CIDR}" ]] && [[ "${SERVICE_IPV4_CIDR}" != "None" ]] ; then
    #Sets the DNS Cluster IP address that would be chosen from the serviceIpv4Cidr. (x.y.z.10)
    DNS_CLUSTER_IP=${SERVICE_IPV4_CIDR%.*}.10
  else
    MAC=$(get_meta_data 'latest/meta-data/network/interfaces/macs/' | head -n 1 | sed 's/\/$//')
    TEN_RANGE=$(get_meta_data "latest/meta-data/network/interfaces/macs/$MAC/vpc-ipv4-cidr-blocks" | grep -c '^10\..*' || true )
    DNS_CLUSTER_IP=10.100.0.10
    if [[ "$TEN_RANGE" != "0" ]]; then
      DNS_CLUSTER_IP=172.20.0.10
    fi
  fi
else
  DNS_CLUSTER_IP="${DNS_CLUSTER_IP}"
fi
```
<br>


#### **- aws-load-balancer-controller 및 Ingress 배포**

폐쇄망 환경에서 ALB Ingress 배포시 wafv2.ap-northeast-2.amazonaws.com 에서 Connection Timeout이 발생한 현상  
```bash
caused by: wafv2.ap-northeast-2.amazonaws.com Post  dial tcp: i/o timeout
```

aws-load-balancer-controller를 배포할 때 Helm 배포를 진행하면서 기본 Values 값에 아래와 같은 설정이 들어있었음(ALB Ingress 배포 참고)  
`Values.yaml`
```bash
# Enable Shield addon for ALB (default true)
enableShield:

# Enable WAF addon for ALB (default true)
enableWaf:

# Enable WAF V2 addon for ALB (default true)
enableWafv2:
```

따라서 폐쇄망 환경에서는 아래와 같이 Helm 배포를 진행하였음  

`aws-load-balancer-controller Helm 배포`
```bash
helm upgrade -i aws-load-balancer-controller eks/aws-load-balancer-controller \
  --set clusterName=ekscluster-name \
  --set serviceAccount.create=false \
  --set serviceAccount.name=aws-load-balancer-controller \
  --set image.repository=222383050459.dkr.ecr.ap-northeast-2.amazonaws.com/opensource-components \
  --set image.tag=aws-load-balancer-controller-v2.2.0 \
  --set enableShield=false \
  --set enableWaf=false \
  --set enableWafv2=false \
  -n kube-system
```
<br>


#### **- ElasticSearch EBS Full**
Kibana에 어느 순간 부터 로그가 쌓이지 않았고, Cloudwatch에 Lambda 로그를 확인 한 결과 아래와 같이 로그가 발생하였음  
```yaml
ERROR Invoke Error
{
    "errorType": "Error",
    "errorMessage": "{\"statusCode\":200,\"responseBody\":{\"took\":0,\"errors\":true}}",
    "stack": [
        "Error: {\"statusCode\":200,\"responseBody\":{\"took\":0,\"errors\":true}}",
        "    at _homogeneousError (/var/runtime/CallbackContext.js:12:12)",
        "    at postError (/var/runtime/CallbackContext.js:29:51)",
        "    at done (/var/runtime/CallbackContext.js:56:7)",
        "    at fail (/var/runtime/CallbackContext.js:68:7)",
        "    at Object.fail (/var/runtime/CallbackContext.js:104:16)",
        "    at /var/task/index.js:43:25",
        "    at IncomingMessage.<anonymous> (/var/task/index.js:177:13)",
        "    at IncomingMessage.emit (events.js:203:15)",
        "    at endReadableNT (_stream_readable.js:1145:12)",
        "    at process._tickCallback (internal/process/next_tick.js:63:19)"
    ]
}
```
위 로그가 명확하지 않아 console.log 로 failedItems를 아래와 같이 추가로 찍어본 결과  
```javascript
post(elasticsearchBulkData, function(error, success, statusCode, failedItems) {
            // 수정완료
            console.log('Failed: ' + JSON.stringify(failedItems));
            console.log('Response: ' + JSON.stringify({ 
                "statusCode": statusCode 
            }));
```

아래와 같은 오류가 발생하였음  
```yaml
{
  "error": {
    "root_cause": [
      {
        "type": "index_create_block_exception",
        "reason": "blocked by: [FORBIDDEN/10/cluster create-index blocked (api)];"
      }
    ],
    "type": "index_create_block_exception",
    "reason": "blocked by: [FORBIDDEN/10/cluster create-index blocked (api)];"
  },
  "status": 403
```
이 오류는 ElasticSearch의 여유 스토리지 공간 부족하여 발생한 문제 였으며 EBS 스토리지 공간을 늘려 조치 완료 하였음 

<br>


#### **- ElasticSearch Sharding 부족**  
Kibana에 어느 순간 부터 로그가 쌓이지 않았고, Cloudwatch에 Lambda 로그를 확인 한 결과 아래와 같이 로그가 발생하였음 (failedItems 을 찍어서 확인할 것)  
Shards가 부족한 현상이 발생하고 있었고, 기존의 index를 삭제하면서 임시로 해결하였다.  
이 후 policy를 생성하여 과거 Index를 관리하는 정책을 만들어 적용하였다.  

```yaml
{
    "index": {
        "_index": "mydata-ubd-bill-api-dev-2021.06.28",
        "_type": "/aws/containerinsights/mydata-cluster-dev/application/ubd/bill-api-dev",
        "_id": "36235500043077433227889076052461137394947113222921781845",
        "status": 400,
        "error": {
            "type": "validation_exception",
            "reason": "Validation Failed: 1: this action would add [10] total shards, but this cluster currently has [999]/[1000] maximum shards open;"
        }
    }
}
```
<br>


#### **- Kibana 로그 섞임**
Kibana화면에서 조회 되는 로그가 섞여서 보이는 현상이 발생  
fluentD.yaml 파일의 configmap에서 multiline_start_regexp을 설정하여 로그를 묶었음  

Log 패턴을 정규 표현식에 맞추어 하나의 로그 그룹으로 묶어 Clodwatch로 전송  

-로그 패턴  
```bash
11:09:04[301] logdata~~~~~~
(T) 11:09:04[301] logdata~~~~~~
logdata~~~~~~
11:09:04[301] logdata~~~~
```

아래와 같이 multiline_start_regexp 수정  
```ruby
<label @containers>
......
<filter **>
  @type concat
  key log
  # 수정완료
  multiline_start_regexp /\((D|E|T|I)\)\s\d{2}[:]\d{2}[:]\d{2}\[\d{3}\]/
  #multiline_start_regexp /^(date:){0,1}\d{4}[-/]\d{1,2}[-/]\d{1,2}/
  separator ""
  flush_interval 5
  timeout_label @NORMAL
</filter>
```
<br>


#### **- wasdk 인증 모듈 이슈**  
인증모듈 라이브러리를 /fsutil/wasdk/jar 추가하였으나 테스트 시 java.lang.UnsatisfiedLinkError 오류 발생  
도커파일에서 기존애 아래와 같이 라이브러리 Path를 잡아 주고 있었고  
```Dockerfile
ENV LD_LIBRARY_PATH="${LD_LIBRARY_PATH}:/fsutil/scp/ba_scp"
ENV JAVA_OPTS="${JAVA_OPTS}:/fsutil/scp/ba_scp"
```

아래와 같이 /fsutil/wasdk/jar 경로를 LD_LIBRARY_PATH 에 추가 해 주었음  
```Dockerfile
ENV LD_LIBRARY_PATH="${LD_LIBRARY_PATH}:/fsutil/scp/ba_scp"
ENV LD_LIBRARY_PATH="${LD_LIBRARY_PATH}:/fsutil/wasdk/jar"
ENV JAVA_OPTS="${JAVA_OPTS}:/fsutil/scp/ba_scp"
```
LD_LIBRARY_PATH 환경 변수에 등록을 해주면 `JAVA_OPTS = "-Djava.library.path=/fsutil/scp/bascp"` 를 주는 것과 동일하기 때문에 
아마도 마지막 변수가 설정되면서 /fsutil/wasdk/jar 경로가 제대로 인식되지 않은 것으로 보여 LD_LIBRARY_PATH와 JVM -D 옵션이 중복되지 않도록 아래와 같이 설정을 변경 하여 해결  
```Dockerfile
ENV LD_LIBRARY_PATH="${LD_LIBRARY_PATH}:/fsutil/scp/ba_scp"
ENV LD_LIBRARY_PATH="${LD_LIBRARY_PATH}:/fsutil/wasdk/jar"
```
<br>


#### **- coredns Configmap 변경**  
EKS Add-ons로 제공 되는 coredns 의 경우 configmap 수정이 불가하다.  
coredns configmap을 수정해서 사용하고 싶은 경우에는 Add-on에서 coredns를 제거하고  
별도로 coredns를 배포하여 변경 건을 배포하여야 한다.  

<br>