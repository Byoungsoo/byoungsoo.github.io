---
layout: post
title: "제목"
author: "Bys"
category: container
date: 2023-11-21 01:00:00
tags: hpa kubernetes eks aws
---

# [HPA](https://kubernetes.io/docs/concepts/overview/components/)

1. cAdvisor가 Pod내 Container들의 Metrics을 수집함.
2. kubelet이 cAdvisor가 노출한 메트릭을 수집함.
3. metric-server가 kubelet으로 부터 metric 리소스를 수집함. 이 주기는 --metric-resolution=15s 옵션에 따라 수집 됨 
4. API서버가 metric-server로부터 metric 리소스를 수집함.?
5. kube-controller(HPA controller)가 metrics API의 데이터를 보고 RS replica를 조정함  (15초)


## 0. 테스트 정보

- HPA테스트를 위해 우선 메트릭 서버는 nacl이 차단되지 않는 존에 위치하게 한다.
- 부하테스기는 각 존 양쪽 2개로 생성한다. 
- 기본 파드도 각 존 양쪽 2개로 생성한다.
- 부하 넣을 때  connection-timeout을 설정해서 지속적으로 들어갈 수 있게 한다. while true; do curl http://php-apache.default --connect-timeout 1; done
  - 이 때 A존 C존에서 각각 차이가 발생함


## 1. 중요
- metrics-server
Cluster addon component that collects and aggregates resource metrics pulled from each kubelet. The API server serves Metrics API for use by HPA, VPA, and by the kubectl top command. Metrics Server is a reference implementation of the Metrics API.
Metrics Server collects resource metrics from Kubelets and exposes them in Kubernetes apiserver through Metrics API for use by Horizontal Pod Autoscaler and Vertical Pod Autoscaler. 
- Metrics API
Kubernetes API supporting access to CPU and memory used for workload autoscaling. To make this work in your cluster, you need an API extension server that provides the Metrics API.

Metrics API는 HPA, VPA또는 사용자가 kubectl을 통해  metric정보를 사용할 수 있도록 CPU나 메모리에 접근할 수 있게 하는 Kubernetes API다. 
즉, API 서버는 HPA, VPA 및 kubectl top 명령에서 사용할 Metrics API를 제공한다. 그리고 Metrics Server는 Metrics API의 참조 구현입니다. 


따라서, 아래 kubectl 커맨드를 통해 메트릭을 조회하면 실제로는 메트릭 서버에서 아래와 같이 로그가 보인다. 
```bash
$ kubectl get --raw "/apis/metrics.k8s.io/v1beta1/nodes/ip-10-20-10-235.ap-northeast-2.compute.internal" | jq '.'

$ kubectl logs -f metrics-server-58fd485c7-nnltl -n kube-system
# srcIP=x-ENI의 주소 중 하나다. 내 로컬 -> API server -> metrics-server로 왔기 때문에. 
I1222 15:01:10.534483       1 handler.go:143] metrics-server: GET "/apis/metrics.k8s.io/v1beta1/nodes/ip-10-20-10-235.ap-northeast-2.compute.internal" satisfied by gorestful with webservice /apis/metrics.k8s.io/v1beta1
I1222 15:01:10.534721       1 httplog.go:129] "HTTP" verb="GET" URI="/apis/metrics.k8s.io/v1beta1/nodes/ip-10-20-10-235.ap-northeast-2.compute.internal" latency="432.784µs" userAgent="kubectl/v1.26.0 (linux/amd64) kubernetes/b46a3f8" audit-ID="ae15fa19-9c33-4ebf-8f7d-15931ba355e0" srcIP="10.20.10.23:40266" resp=200
```

그리고 평소에 찍히는 로그를 살펴보자.
```bash
$ kubectl logs -f metrics-server-58fd485c7-nnltl -n kube-system

# Kubelet으로부터 메트릭 정보를 수집하고 있다. 
I1222 15:01:24.847741       1 scraper.go:115] "Scraping metrics from nodes" nodeCount=2
I1222 15:01:24.855038       1 scraper.go:137] "Scraping node" node="ip-10-20-10-235.ap-northeast-2.compute.internal"
I1222 15:01:24.857187       1 scraper.go:137] "Scraping node" node="ip-10-20-11-91.ap-northeast-2.compute.internal"
I1222 15:01:24.877046       1 scraper.go:172] "Scrape finished" duration="29.273444ms" nodeCount=2 podCount=17
```

```bash
# 아래의 로그도 주기적으로 관찰된다. 
# $ kubectl get --raw "/apis/metrics.k8s.io/v1beta1" | jq '.' 와 동일하며 아래 Json과 같은 결과다. 
I1222 15:01:32.412952       1 handler.go:143] metrics-server: GET "/apis/metrics.k8s.io/v1beta1" satisfied by gorestful with webservice /apis/metrics.k8s.io/v1beta1
I1222 15:01:32.413091       1 httplog.go:129] "HTTP" verb="GET" URI="/apis/metrics.k8s.io/v1beta1" latency="463.055µs" userAgent="Go-http-client/2.0" audit-ID="bd8de76a-3c9d-48a8-8a1a-01f422fab985" srcIP="10.20.10.23:55758" resp=200
I1222 15:01:32.414641       1 handler.go:143] metrics-server: GET "/apis/metrics.k8s.io/v1beta1" satisfied by gorestful with webservice /apis/metrics.k8s.io/v1beta1
I1222 15:01:32.414739       1 httplog.go:129] "HTTP" verb="GET" URI="/apis/metrics.k8s.io/v1beta1" latency="1.075269ms" userAgent="Go-http-client/2.0" audit-ID="6b5f85c4-91fb-4281-accd-e2fe25839b51" srcIP="10.20.10.23:55758" resp=200
I1222 15:01:32.415022       1 handler.go:143] metrics-server: GET "/apis/metrics.k8s.io/v1beta1" satisfied by gorestful with webservice /apis/metrics.k8s.io/v1beta1
I1222 15:01:32.415107       1 httplog.go:129] "HTTP" verb="GET" URI="/apis/metrics.k8s.io/v1beta1" latency="274.007µs" userAgent="Go-http-client/2.0" audit-ID="15b0738b-5bc6-44e2-972c-0bf13207c0b8" srcIP="10.20.10.23:55758" resp=200
I1222 15:01:32.415125       1 handler.go:143] metrics-server: GET "/apis/metrics.k8s.io/v1beta1" satisfied by gorestful with webservice /apis/metrics.k8s.io/v1beta1
I1222 15:01:32.415195       1 httplog.go:129] "HTTP" verb="GET" URI="/apis/metrics.k8s.io/v1beta1" latency="219.997µs" userAgent="Go-http-client/2.0" audit-ID="60b6b52b-0233-4c3b-9f26-9dca60190563" srcIP="10.20.10.23:55758" resp=200
I1222 15:01:32.415411       1 handler.go:143] metrics-server: GET "/apis/metrics.k8s.io/v1beta1" satisfied by gorestful with webservice /apis/metrics.k8s.io/v1beta1
I1222 15:01:32.415563       1 httplog.go:129] "HTTP" verb="GET" URI="/apis/metrics.k8s.io/v1beta1" latency="301.734µs" userAgent="Go-http-client/2.0" audit-ID="7f23ba0c-bdc6-4fff-a6d7-972dc4c3231f" srcIP="10.20.10.23:55758" resp=200
```
```json
{
  "kind": "APIResourceList",
  "apiVersion": "v1",
  "groupVersion": "metrics.k8s.io/v1beta1",
  "resources": [
    {
      "name": "nodes",
      "singularName": "",
      "namespaced": false,
      "kind": "NodeMetrics",
      "verbs": [
        "get",
        "list"
      ]
    },
    {
      "name": "pods",
      "singularName": "",
      "namespaced": true,
      "kind": "PodMetrics",
      "verbs": [
        "get",
        "list"
      ]
    }
  ]
}
```

```bash
# 아래도 주기적으로 관찰되는 로그이며 이는 아마도 php-apche hpa에의해 주기적으로 15초마다 조회되는 결과로 보인다.  
I1222 15:01:37.041375       1 handler.go:143] metrics-server: GET "/apis/metrics.k8s.io/v1beta1/namespaces/default/pods" satisfied by gorestful with webservice /apis/metrics.k8s.io/v1beta1
I1222 15:01:37.041560       1 httplog.go:129] "HTTP" verb="LIST" URI="/apis/metrics.k8s.io/v1beta1/namespaces/default/pods?labelSelector=run%3Dphp-apache" latency="4.32772ms" userAgent="kube-controller-manager/v1.21.14 (linux/amd64) kubernetes/b07006b/system:serviceaccount:kube-system:horizontal-pod-autoscaler" audit-ID="de1229ce-5f8f-4636-8698-0ff3003aca05" srcIP="10.20.11.208:32858" resp=200

I1222 15:01:52.104167       1 handler.go:143] metrics-server: GET "/apis/metrics.k8s.io/v1beta1/namespaces/default/pods" satisfied by gorestful with webservice /apis/metrics.k8s.io/v1beta1
I1222 15:01:52.104352       1 httplog.go:129] "HTTP" verb="LIST" URI="/apis/metrics.k8s.io/v1beta1/namespaces/default/pods?labelSelector=run%3Dphp-apache" latency="3.059605ms" userAgent="kube-controller-manager/v1.21.14 (linux/amd64) kubernetes/b07006b/system:serviceaccount:kube-system:horizontal-pod-autoscaler" audit-ID="b57ab53f-0194-41e2-99b1-50c7dc429e03" srcIP="10.20.11.208:32858" resp=200

I1222 15:02:07.127963       1 handler.go:143] metrics-server: GET "/apis/metrics.k8s.io/v1beta1/namespaces/default/pods" satisfied by gorestful with webservice /apis/metrics.k8s.io/v1beta1
I1222 15:02:07.128194       1 httplog.go:129] "HTTP" verb="LIST" URI="/apis/metrics.k8s.io/v1beta1/namespaces/default/pods?labelSelector=run%3Dphp-apache" latency="4.949269ms" userAgent="kube-controller-manager/v1.21.14 (linux/amd64) kubernetes/b07006b/system:serviceaccount:kube-system:horizontal-pod-autoscaler" audit-ID="5f545f72-bb1b-4cce-a7e6-a5681235f1bc" srcIP="10.20.11.208:32858" resp=200

I1222 15:02:22.205786       1 handler.go:143] metrics-server: GET "/apis/metrics.k8s.io/v1beta1/namespaces/default/pods" satisfied by gorestful with webservice /apis/metrics.k8s.io/v1beta1
I1222 15:02:22.206026       1 httplog.go:129] "HTTP" verb="LIST" URI="/apis/metrics.k8s.io/v1beta1/namespaces/default/pods?labelSelector=run%3Dphp-apache" latency="3.820725ms" userAgent="kube-controller-manager/v1.21.14 (linux/amd64) kubernetes/b07006b/system:serviceaccount:kube-system:horizontal-pod-autoscaler" audit-ID="b591499b-e8f3-4313-9f7a-ab2395eaac70" srcIP="10.20.11.208:32858" resp=200
```


## 2. 테스트 결과 중요한 것! 
우선 메트릭 서버가 무너진 존에 위차하게 되면 그 때는 HPA는 동작 안함.
테스트시에는 통신 가능한 존에 위치한다고 가정하고 테스트 진행. 

1. C zone이 무너졌을 때, kube-controller가 API서버와 통신이 안되는 현상이 있음!
   - 결국 kube-controller의 hpa, node controller 등이 내 vpc의 데이터를 확인하기 위해서는 eks-owned-ENI를 통해서 통신이 되어야 하는데 일단 이것이 불가한 현상이 있음
    ```bash 
    Events:
      Type     Reason                        Age                 From                       Message
      ----     ------                        ----                ----                       -------
      Normal   SuccessfulRescale             43m (x2 over 10h)   horizontal-pod-autoscaler  New size: 2; reason: Current number of replicas below Spec.MinReplicas
      Warning  FailedComputeMetricsReplicas  43m                 horizontal-pod-autoscaler  invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: did not receive metrics for any ready pods
      Warning  FailedGetResourceMetric       43m                 horizontal-pod-autoscaler  failed to get cpu utilization: did not receive metrics for any ready pods
      Normal   SuccessfulRescale             39m (x4 over 27h)   horizontal-pod-autoscaler  New size: 4; reason: cpu resource utilization (percentage of request) above target
      Normal   SuccessfulRescale             39m (x3 over 27h)   horizontal-pod-autoscaler  New size: 8; reason: cpu resource utilization (percentage of request) above target
      Normal   SuccessfulRescale             39m                 horizontal-pod-autoscaler  New size: 10; reason:
      Normal   SuccessfulRescale             28m                 horizontal-pod-autoscaler  New size: 7; reason: All metrics below target
      Normal   SuccessfulRescale             28m (x2 over 22h)   horizontal-pod-autoscaler  New size: 5; reason: All metrics below target
      Warning  FailedComputeMetricsReplicas  23m (x70 over 27h)  horizontal-pod-autoscaler  invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server is currently unable to handle the request (get pods.metrics.k8s.io)
      Warning  FailedGetResourceMetric       23m (x67 over 27h)  horizontal-pod-autoscaler  failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server is currently unable to handle the request (get pods.metrics.k8s.io)
      Warning  FailedGetResourceMetric       23m                 horizontal-pod-autoscaler  failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: Get "https://172.16.104.10:443/apis/metrics.k8s.io/v1beta1/namespaces/default/pods?labelSelector=run%3Dphp-apache": stream error: stream ID 1844467; INTERNAL_ERROR; received from peer
      Warning  FailedComputeMetricsReplicas  23m                 horizontal-pod-autoscaler  invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: Get "https://172.16.104.10:443/apis/metrics.k8s.io/v1beta1/namespaces/default/pods?labelSelector=run%3Dphp-apache": stream error: stream ID 1844467; INTERNAL_ERROR; received from peer
      Warning  FailedComputeMetricsReplicas  22m (x4 over 27h)   horizontal-pod-autoscaler  invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server was unable to return a response in the time allotted, but may still be processing the request (get pods.metrics.k8s.io)
      Warning  FailedGetResourceMetric       22m (x2 over 27h)   horizontal-pod-autoscaler  f
    ```
   - 하지만 다른 Zone에 ENI를 사용하지 못하는 이유는 ? 
   - curl로 부하를 넣을 때에도 nslookup이 안됨. kube-dns동작도 안됨. Resolving timed out after 1000 milliseconds


2. A zone이 무너졌을 때, 정상 동작 됨.
    ```bash
    Normal   SuccessfulRescale             9m47s                horizontal-pod-autoscaler  New size: 2; reason: All metrics below target
    Normal   SuccessfulRescale             2m30s (x5 over 27h)  horizontal-pod-autoscaler  New size: 4; reason: cpu resource utilization (percentage of request) above target
    Warning  FailedGetResourceMetric       2m5s (x3 over 27h)   horizontal-pod-autoscaler  failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: an error on the server ("Internal Server Error: \"/apis/metrics.k8s.io/v1beta1/namespaces/default/pods?labelSelector=run%3Dphp-apache\": Post \"https://172.20.0.1:443/apis/authorization.k8s.io/v1/subjectaccessreviews?timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)") has prevented the request from succeeding (get pods.metrics.k8s.io)
    Warning  FailedComputeMetricsReplicas  2m5s (x3 over 27h)   horizontal-pod-autoscaler  invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: an error on the server ("Internal Server Error: \"/apis/metrics.k8s.io/v1beta1/namespaces/default/pods?labelSelector=run%3Dphp-apache\": Post \"https://172.20.0.1:443/apis/authorization.k8s.io/v1/subjectaccessreviews?timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)") has prevented the request from succeeding (get pods.metrics.k8s.io)
    ```
   - 간간히 connection timeout이 떨어지지만 요청은 감
   ```bash
   while true; do curl http://php-apache.default --connect-timeout 1; done
    OK!curl: (28) Connection timeout after 1001 ms
    curl: (28) Connection timeout after 1001 ms
    OK!OK!OK!OK!OK!OK!curl: (28) Connection timeout after 1001 ms
    curl: (28) Connection timeout after 1000 ms
    OK!curl: (28) Connection timeout after 1000 ms
    OK!curl: (28) Connection timeout after 1000 ms
   ```
   - hpa 동작 함
   ```bash
   k get hpa --watch
    NAME         REFERENCE               TARGETS   MINPODS   MAXPODS   REPLICAS   AGE
    php-apache   Deployment/php-apache   5%/50%    2         10        9          32h
    php-apache   Deployment/php-apache   11%/50%   2         10        9          32h
    php-apache   Deployment/php-apache   11%/50%   2         10        9          32h
    php-apache   Deployment/php-apache   10%/50%   2         10        9          32h
    php-apache   Deployment/php-apache   8%/50%    2         10        9          32h
   ```

Zone C에 대한 NACL 차단 이 후, 발생. 172.16.104.10 IP는 Control Plane에서 바라보는 API server IP이다. 
```bash
k describe hpa php-apache
Name:                                                  php-apache
Namespace:                                             default
Labels:                                                <none>
Annotations:                                           <none>
CreationTimestamp:                                     Wed, 21 Dec 2022 17:18:52 +0900
Reference:                                             Deployment/php-apache
Metrics:                                               ( current / target )
  resource cpu on pods  (as a percentage of request):  82% (165m) / 20%
Min replicas:                                          1
Max replicas:                                          10
Deployment pods:                                       4 current / 4 desired
Conditions:
  Type            Status  Reason                   Message
  ----            ------  ------                   -------
  AbleToScale     True    SucceededGetScale        the HPA controller was able to get the target's current scale
  ScalingActive   False   FailedGetResourceMetric  the HPA was unable to compute the replica count: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server is currently unable to handle the request (get pods.metrics.k8s.io)
  ScalingLimited  True    ScaleUpLimit             the desired replica count is increasing faster than the maximum scale rate
Events:
  Type     Reason                   Age                     From                       Message
  ----     ------                   ----                    ----                       -------
  Warning  FailedGetResourceMetric  8m17s (x162 over 3h8m)  horizontal-pod-autoscaler  (combined from similar events): failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: Get "https://172.16.104.10:443/apis/metrics.k8s.io/v1beta1/namespaces/default/pods?labelSelector=run%3Dphp-apache": stream error: stream ID 1288691; INTERNAL_ERROR; received from peer
  Warning  FailedGetResourceMetric  3m22s (x54 over 3h41m)  horizontal-pod-autoscaler  failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server is currently unable to handle the request (get pods.metrics.k8s.io)
```

<br><br><br>

> Ref: [kubernetes-sigs/metrics-server](https://github.com/kubernetes-sigs/metrics-server)
> Ref: [High Availability](https://kubernetes-sigs.github.io/metrics-server/#:~:text=command%20line%20flag-,High%20Availability,-Latest%20Metrics%20Server)
> Ref: [metric-server 가용성](https://nangman14.tistory.com/81)
> Ref: [Resource metrics pipeline](https://kubernetes.io/docs/tasks/debug/debug-cluster/resource-metrics-pipeline/)