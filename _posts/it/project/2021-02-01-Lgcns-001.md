---
layout: post
title: "Project - LGCNS MSA Outer 교육과정 개발"
author: "Bys"
category: project
date: 2021-01-01 01:00:00
tags: project issue
---

### **목차**

## 1. API Gateway  
+ ### 1.1 개요  
+ ### 1.2 필요성 및 장점  
+ ### 1.3 API Gateway를 사용해야 하는 필요성  

## 2. Container Management Platform  
+ ### 2.1 사전 지식
+ ### 2.2 개요  
+ ### 2.3 필요성  
+ ### 2.4 장점  
  
## 3. Service Mesh  
+ ### 3.1 개요  
+ ### 3.2 필요성  
+ ### 3.3 장점  

## 4. Backing Service (Message Queue / Cache)  
+ ### 4.1 생략  

## 5. Telemetry (Tracing / Monitoring / 로그 취합 / 분석)  
+ ### 5.1 개요  
+ ### 5.2 필요성  
+ ### 5.3 주요기능  

## 6. CI/CD  
+ ### 6.1 개요  
+ ### 6.1 필요성  
+ ### 6.1 장점 및 특징  

<br><br>


## 1. API Gateway  

### 1.1 개요  
마이크로서비스 아키텍처 환경에서 핵심적인 관문 역할을 담당합니다. 
<br>

### 1.2 필요성 및 장점  
MSA 환경에서 사용자가 서비스를 직접 호출할 때 생기는 문제점
- 엔드포인트 관리의 필요성  
- 공통 기능 중복개발  
- 보안 취약성  

마이크로서비스 아키텍처 환경에서는 서비스들이 분리되고 나누어지게 되다보니 각 서비스별로 호출해야 하는 엔드포인트가 달라지게 됩니다.  
이렇게 되면 관리해야 하는 엔드포인트의 수도 늘어나게 되고, 각 서비스별로 인증 및 인가에 대한 기능, 트래픽을 로깅할 수 있는 기능 등에 대해서 중복개발이 필요하게 됩니다.  
또한 내부 서비스가 사용자에게 직접 노출이되어 보안에 취약하다고 할 수 있습니다.  
<br>

### 1.3 API Gateway를 사용해야 하는 필요성  
- 관문 역할  
- End Point를 통합  
- 공통기능을 제공  
- 라우팅 및 로드밸런싱  
- 프로토콜 변환  

API Gateway를 사용하게 되면 API Gateway가 없을 때 보다 훨씬 큰 이점을 가져갈 수 있습니다.  
마이크로 서비스 아키텍처 환경에서 모든 API 요청은 API Gateway를 통하게 됩니다.  
요청이 이 곳을 통과하기 때문에 각 서비스별로 필요했던 공통 기능을 API Gateway에서 제공해주므로써 각 마이크로 서비스에서는 기능에 대한 중복 개발이 필요 없어지게 됩니다.  
또한 사용자 요청에 대해서 접근 제어 및 트래픽을 모니터링하고 보안기능을 제공하여 전체적인 마이크로 서비스를 보호를 담당하게 됩니다.  
이렇게 API Gateway는 모든 서비스 요청에 대한 일원화를 제공하며 각 서비스별 중복기능에 대한 통합, 트래픽에 대한 제어 및 보안 등의 다양한 기능을 제공하며 마이크로 서비스 아키텍처 환경에서 없어서는 안되는 필수적인 구성요소 입니다.  

<br><br>

## 2. Container Management Platform  

### 2.1 사전 지식
Container & Docker  
- 컨테이너는 App을 실행시키는데 필요한  바이너리, 라이브러리, 구성 파일 패키지로 묶어 마치 별도의 서버인 것처럼 사용할 수 있게 만든 기술.  
- 컨테이너는 가볍고, 빠르며, 확장성이 좋은 특징을 가지고 있음.  
Docker는 가장 널리 사용되는 컨테이너 기술.  

<br>

Pod  
- Kubernetes에서 최소 배포 단위. Kubernetes에서는 Pod 단위로 배포를 진행  
- Pod는 하나 이상의 컨테이너를 포함하고 있는 논리적인 묶음 단위  
(단, 업무 컨테이너는 하나의 Pod에 하나의 컨테이너만 권고!)Ex) 메인이 되는 컨테이너 A와, A의 log 수집을 위한 컨테이너, Service Mesh를 위한 Sidecar Container 등 을 하나로 묶어 Pod 단위로 배포  

<br>

### 2.2 개요  
MSA 환경에서 적합한 기술로 컨테이너가 사용되며 컨테이너의 사용이 많아지기 시작했습니다.  
이에 컨테이너 관리의 필요성이 증가하였고 여기저기 분산된 컨테이너 환경에서 운영 및 관리를 효율적으로 하기 위해 Orchestration Tool이 도입되었습니다.   
Container Management Platform은 결국 컨테이너 환경에서 효율적인 운영 및 관리를 위한 서비스의 장애 복구(Auto-Healing), 로드밸런싱, 라우팅, 스케줄링 등의 다양한 기능을 제공해주는 역할을 합니다.  
Orchestration Tool로는 대표적인 Kubernetes가 있으며 이 외에도 AWS ECS, Docker Swarm, Apahce Mesos등이 존재합니다.  

<br>

### 2.3 필요성  
MSA 환경에서 Orchestration Toool 이 없다면? 
- 수작업으로 서비스 등록이 필요함  
- 다량의 컨테이너 배포를 직접해야 함  
- 컨테이너의 스케줄링을 직접해야 함  
- 컨테이너 장애 발생 시 정상 동작여부에 대한 확인 및 복구 필요  
<br>

컨테이너 및 Pod는 고정 된 IP를 가지고 있지 않습니다. 새로운 컨테이너나 Pod가 배포 될 때마다 IP가 변동 되는데 운영자는 이 변경 된 IP를 서비스로 직접 등록 해주는 일을 해야 합니다.  
또한 컨테이너를 배포 할 때 한 두개의 컨테이너 배포라면 상관이 없겠지만, 대량의 컨테이너를 배포해야 하는 경우 직접 수동으로 배포를 해주어야 하는 어려움이 있으며 컨테이너를 배포할 위치 즉, 어떤 서버에 컨테이너를 배포할지에 대한 부분을 직접 생각하고 작업을 진행해주어야 합니다.  

이 외에도 다양한 어려움이 존재하는데 배포 이후에도 서비스에 장애가 발생할 경우 수작업으로 컨테이너를 재기동 해주어야 한다는지 지속적인 모니터링과 관리의 필요성이 증가하게 됩니다.  
따라서 한 두 개의 컨테이너는 괜찮지만 MSA 환경에서 엔터프라이즈 급 수준의 컨테이너 관리를 위해서는 Orchestration Tool은 필수적 입니다.  

<br>

### 2.4 장점
운영환경에서 다양한 요구사항에 대한  문제를 해결하기 위해 Container Management Platform이 등장하였고 아래와 같은 이점을 가져감  
- 컨테이너 자동 배치 및 복제  
- 컨테이너 그룹에 대한 로드 밸런싱  
- 컨테이너 장애 복구  
- 클러스터 외부에 서비스 노출  
- 컨테이너 추가 또는 제거로 확장 및 축소  
- 컨테이너 서비스간의 인터페이스를 통한 연결 및  네트워크 포트 노출 제어  

<br><br>

## 3. Service Mesh  

### 3.1 개요  
마이크로 서비스 간 통신을 관리하기 위해 Service Mesh 도입  
Service Mesh의 주요 목적은 네트워크 내부에서 서비스 간 트래픽을 라우팅 하고 관리하는 역할  
서비스 메시는 마이크로서비스 아키텍처 환경에서 마이크로 서비스 수가 증가함에 따라  이에 따른 내부 마이크로 서비스간 통신을 관리하기 위한 관리 체계라고 할 수 있습니다.  

<br>

### 3.2 필요성  

![lgc01](/assets/it/project/lgcns/lnd/lgc01.png){: width="40%" height="auto"}  

**Service Mesh가 없는 아키텍처의 문제점**  
- 복잡한 연결 구조 때문에 장애 추적이 어려움  
- 장애가 다른 서비스로 전파 될 수 있음  
- 공통 기능을 각 서비스마다 구현해야 함  
- 서비스간 연결이 강하게 묶여 있음  
<br>
마이크로 서비스 아키텍처 환경에서는 서비스의 수가 증가하면서 각 서비스간 연결이 복잡한 구조를 가지게 되었습니다.  
복잡한 연결 구조에서는 장애가 발생할 경우 장애의 추적이 어려워 집니다. 어떤 서비스에서 장애가 발생했는지 파악하기 까지 꽤 많은 시간이 걸릴지도 모릅니다.  

<br> 
서비스간 직접적인 통신은 한 서비스의 장애가 다른 서비스로의 장애까지 전파 되는 현상을 초래할 수 있습니다. 
위의 그림에서 서비스 B에 장애가 발생하면 서비스 A는 B에게 응답을 받지 못하고 계속 응답을 기다리는 대기상태가 됩니다. 
이런 상황에서 지속적으로 A가 B를 호출하게 될 경우 서비스 A의 모든 자원이 B의 응답을 기다리게 되고 다른 요청을 처리할 자원이 없게 되며 결국 서비스 A 까지 장애가 전파되버리고 맙니다.  

<br>
외부에서 내부로 들어오는 통신의 경우 API Gateway에서 인증 및 인가, 로깅 및 모니터링 등의 공통기능을 제공해주는 반면 외부에서 들어오는 트래픽이 아닌 내부 마이크로 서비스 간 통신은 서비스 모듈에 별도 공통기능이 추가로 필요해 하게됩니다.  
즉, 서비스 A가 서비스 B에게 요청을 하는 상황에서 B는 해당 요청이 정상적인 권한으로 요청하는 것인지 확인이 필요 하며 운영자 입장에서는 이러한 트래픽들에 대한 로깅과 모니터링이 필요합니다.  
그럼 이런 공통기능을 각 서비스 별로 모두 구현해야 하게 되는 중복 개발의 필요성이 생기게 됩니다.  

<br>
확장성에도 문제가 있습니다.  
트래픽이 많은 상황에서 B의 서비스 개수를 늘리려고 하였을 때 추가 된 서비스 B의 부하분산 작업이 어려워지게 됩니다.  
이는 모두 마이크로 서비스간 연결이 직접적으로 이루어져 있기 때문에 발생하게 되며 이를 효율적으로 관리하고 개선하고자 나온 개념이 서비스 메시의 개념입니다.  

<br>

### 3.3 장점  
Service Mesh는 복잡한 분산 컴퓨팅 문제를 관리하여, 개발자의 부담을 줄이고 생산성 향상에 기여  

- 확장성 - 서비스 디스커버리, 라우팅 지원 및 로드밸런싱  
- 탄력성 - 셀프 힐링을 지원, 장애 전파를 방지  
- 보안성 - 인증 및 권한 지원, 암호화 및 TLS 키 관리 지원  
- 추적성 - Pod 레벨에서 추적을 제공하여 언어의 제약이 없음  

<br>

자세한 내용은 아래의 그림을 보면 쉽게 이해할 수 있습니다.  

![lgc02](/assets/it/project/lgcns/lnd/lgc02.png){: width="40%" height="auto"}  

<OSS Istio Sidecar Pattern의 Service Mesh>  

위 그림은 현재 서비스 메시의 구현에 많이 사용되고 있는 사이드카 패턴의 사이드 메시 입니다.  (사이드카 패턴은 서비스 코드와 결합성이 낮아 많이 사용되어짐. 사이드카 패터이란? 참고: https://blog.leocat.kr/notes/2019/02/16/cloud-sidecar-pattern)  

기존과 비교하여 추가 된 것은 사이드카 프록시라는 별도의 컨테이너 서비스가 추가 되었으며 이 프록시는 각 서비스의 모든 통신을 담당하게 됩니다.  

- 서비스메시 도입 전  
(컨테이너A → 컨테이너B)  

- 서비스메시 도입 후  
(컨테이너A → 사이드카 프록시A → 사이드카 프록시 B→ 컨테이너B)  

기존 직접 통신에서 중간에 사이드카 프록시를 통해서 통신하게 됩니다. 이렇게 될 경우 서비스 메시가 도입되지 않았을 때 생기는 많은 문제점을 보안할 수 있게 됩니다.  

<br>

첫 번째로 모니터링이 쉬워집니다.  
사이드카 프록시에서 서비스 간 상호작용 및 각 서비스별 호출을 모니터링하고 추적 및 분석도구로 해당 정보들을 보내주게 됩니다.  
이렇게 되면 운영자는 장애 발생시 어떤 서비스에서 장애가 발생했는지 추적이 쉬워지게 되며 로깅 정보를 쉽게 획득 할 수 있습니다.  
 
또한 Polyglot 환경(분산 시스템에서 각 서비스들이 다양한 언어로 개발 되어진 환경)에서 서비스 메쉬는 어플리케이션 레벨이 아닌 Pod레벨에서 추적을 제공하여 언어의 제약이 없다는 장점을 가지고 있습니다.  
이는 서비스 컨테이너를 개발한 언어와 별개로 사이드카 프록시에서 모니터링 기능 및 추적, 분석 도구를 제공해주므로써 서비스간 결합이 약하게 묶여 있어 가능해지는 일 입니다.  

<br>

두 번째로는 장애 전파를 방지할 수 있습니다. 
서비스 A에서 서비스 B를 호출할 때 만약 B에서 장애가 발생하여 응답이 없는 경우 중간에 있는 사이드카 프록시에서는 Circuit Breaker의 역할을 해주므로써 
연결을 끊어버리고 A에게 오류 응답을 주어 더 이상 응답 대기상태가 되도록 하지 않습니다. 

<br>

세 번째로는 공통 기능을 지원합니다.  
내부 서비스 간 인증 및 인가, 보안에 관련된 기능에 대해 지원해줍니다. 이는 각 서비스별로 개발해야하는 공통기능이지만 서비스 메시에서 제공해주므로써 중복개발을 방지하고 
개발자들은 서비스코드에만 집중할 수 있도록 도와줍니다.  

<br>

네 번째로는 라우팅 및 로드밸런싱 입니다. 
서비스가 다른 서비스를 호출 할 때 사이드카 프록시에서 라우팅 및 로드밸런싱을 지원합니다.  

<br><br>

## 4. Backing Service (Message Queue / Cache)  
생략

<br><br>

## 5. Telemetry (Tracing / Monitoring / 로그 취합 / 분석)  

### 5.1 개요  
Telemetry는 마이크로 서비스 아키텍처 환경에서 분산된 서비스들의 모니터링, 로깅, 추적 분석을 위한 서비스 제공하는 역할을 수행합니다.  

<br>

### 5.2 필요성  
MSA 환경에서는 분산된 서비스의 복잡성으로 인하여 호출관계 추적, 로그 확인 등 어려움 증가 하였습니다.  
분산된 서비스로 인해 서비스의 수가 늘어나고 모니터링 대상 로그도 각 서비스마다 분산되어 저장 되다 보니 이를 통합하여 관리할 필요성이 증가하였고, 서비스 간 복잡한 호출 관계로 인하여 어떤 서비스에서 어떤 서비스로 호출이 되었는지 호출 구조의 관리가 필요해졌습니다.  

<br>

### 5.3 주요기능  
모니터링 대상 및 항목에 따라 요건 및 측정 Metric 별 모니터링 도구 적용 필요  
- Logging  
분산된 마이크로서비스 아키텍처 환경에서 각 서비스의 로그들을 수집하여 통합으로 로그를 저장 관리 하고 시각화 툴을 통해 보여주는 서비스 입니다.  
각 서비스에 배포된 Agent들이 로그를 수집하고 중앙에 있는 로그 저장소로 전달 하는 역할을 합니다.  


Ex) OSS - ELK, EFK 

![lgc03](/assets/it/project/lgcns/lnd/lgc03.png){: width="40%" height="auto"}  

- EFK는 Elasticsearch(E), Fluentd(F), Kibana(K)로 구성되며, Logging의 목적으로 사용 
- Fluentd가 배포된 호스트에서 로그를 필터링하고 모으는 Aggregator 역할 
- Elasticsearch가 모인 로그를 저장 
- 저장된 로그를 Kibana가 Visualize하는 역할 수행 
- Fluentd 대신 Logstash를 사용할 경우 ELK 
<br>

위 예시를 보면 Fluentd는 로그를 수집하는 역할을 위해 각 서비스에 Agent형식으로 같이 배포가 되고 수집된 로그들은 Elasticsearch 라고 하는 통합 로그 저장 관리소로 로그를 보냅니다. 
Kibana는 Elasticsearch에 모인 로그를 가져와 운영자 혹은 개발자들에게 보기 쉽게 정보를 시각화 하여 보여줍니다. 

- Tracing  

추적관리(Tracing)은 Event가 일어난 순서대로 나열해서 보여주는 서비스로 분산 환경에서 어떤 부분에 오류가 발생했는지를 파악할 수 있도록 추적 프로세스를 제공하는 서비스입니다. 

Ex) AWS X-Ray 

 ![lgc04](/assets/it/project/lgcns/lnd/lgc04.png){: width="40%" height="auto"}  

- 요청에 대한 전체 과정 추적 가능 
- 어느 위치에 성능이슈가 있는지 파악 가능 
- 레이턴시, http 상태코드 및 메타정보 분석가능 
<br>
위 의 그림은 AWS X-Ray를 사용하는 한화생명 SFA 시스템의 Service Map 입니다.  
사용자의 최초 요청부터 시작하여 어플리케이션간 통신하는 과정을 보여줍니다. 통신에 대한 흐름을 맵 형태로 잘 보여주고 있어 전체적인 과정을 추적하기 쉽고 흐름을 파악하기가 쉽습니다.  
또한 X-Ray의 추적기능을 통해 요청 경로를 따라가며 어떤 위치에서 성능이슈가 있는지 파악이 가능하며 색으로 표시된 오류를 체크하고 View Traces등을 누르면 각 서비스별로 어떤 Fault, Error 등이 발생하였는지 정보를 제공해주고 있습니다.  
<br>

- Monitoring 

모니터링(Monitoring)은 성능(Performance) 또는 효율성(Efficiency)를 확인하는 서비스로, 각 대상에게서 수집한 Metric을 통해 대상 리소스의 사용률 등을 수치로 표현하여 제공하는 서비스입니다.  
<br>

Ex) AWS CloudWatch  

![lgc05](/assets/it/project/lgcns/lnd/lgc05.png){: width="70%" height="auto"}  

- 리소스 사용률, 성능, 상태에 대한 파악이 가능  
- 장애 발생시 신속하게 문제를 진단 할 수 있음 
- 모니터링 대상 및 항목에 따라 요건 및 측정 Metric 별 모니터링 도구 적용 필요 
<br>
위 의 그림은 AWS CloudWatch를 사용하는 한화생명 SFA 시스템의 모니터링 Dashboard 입니다.  
모니터링은 각 대상에게서 수집한 Metric을 통해 대상 리소스의 사용률 등을 수치로 표현하는 기능을 수행합니다.  
운영자는 시스템 의 전반적인 리소스 사용률을 체크하여 비용절감의 효과를 가져올 수 있고, 어플리케이션의 성능을 확인하여 개선 작업을 선행 할 수 있습니다.  
메트릭 정보를 통한 장애에 대한 사전 예방 및 장애의 신속한 대응을 할 수 있게 해줍니다.  

<br><br>


## 6. CI/CD  

### 6.1 개요  
CI/CD는 어플리케이션 개발 단계를 자동화하여 어플리케이션을 보다 짧은 주기로 고객에게 제공하는 방법입니다.  
지속적인 통합, 지속적인 제공, 지속적인 배포를 기본 개념으로 하고 있습니다.   

- CI(Continuous Integration)  
지속적인 통합으로 어플리케이션에 여러 개발자들의 코드 변경사항이 정기적으로 빌드 및 테스트되어 공유 레파지토리(SVN, Git 등) 에 하나로 통합 및 병합하는 과정 입니다.  

- CD(Continuous Delivery)  
지속적인 서비스 제공으로 변경된 어플리케이션이 버그 테스트를 거쳐 레파지토리에 업로드되는 것  

- CD(Continuous Deployment)  
지속적인 배포로 운영환경까지 자동으로 릴리즈 하는 것  
<br>

### 6.1 필요성  
MSA 환경에서는 Agile 방법론에 따라 기능 단위의 빠른 개발 및 적용을 반복하기 때문에 소스 변경이 빈번해졌습니다.  
따라서 소스의 변경, 빌드, 테스트, 배포 등의 기존 사이클을 자동화하고, 이를 통해 불필요한 시간을 줄여 지속적인 출시와 짧은 단위의 사이클로 출시를 가능하게 하고자 하였습니다.  
<br>

### 6.1 장점 및 특징  

![lgc06](/assets/it/project/lgcns/lnd/lgc06.png){: width="70%" height="auto"}   

CI/CD를 적용하게 되면 자동화 과정을 통해 지속적인 출시와 짧은 출시 기간을 가져갈 수 있습니다.  
이는 Agile방법론에서 이야기하는 "끊임없이 개발하고 수정하는 일을 반복하면서 고객이 가장 만족할 수 있는 방향으로 소프트웨어를 개발" 하는 방식을 구현할 수 있는 도구입니다.  

CI/CD는 사전에 구축된 파이프라인의 단계에 따라 진행이 됩니다.  
여기서 파이프라인은 개발자들이 코드로 정의해놓은 단계이며 일반적으로 빌드 → 테스트 → 릴리즈 → 배포의 단계를 거치게 됩니다.  


각각의 단계를 살펴보면 빌드 단계에서는 소스를 컴파일 및 패키징하게 되며 빌드 단계에서 Sonarqube 등의 소스 검사 도구를 도입하여 코드상의 보안 취약점, 버그, 중복 코드 등을 발견하여 품질을 향상 시킬 수 있습니다.  

릴리스 단계에서는 패키징된 어플리케이션과 Docker Image파일등을 레파지토리로 제공하며 배포의 단계에서는 Branch(master, stage, develop ...) 등을 을 확인하여 각 환경에 맞게 어플리케이션을 배포하게 됩니다.  

배포가 실행 되기전에는 Clair, Anchore와 같은 툴을 활용하여 Container Image에 대한 검증, 분석 및 취약점을 점검한 후 배포를 할 수도 있습니다.  

 
 

이와 같이 CI/CD의 자동화는 개발자가 소스만 레파지토리로 반영하게 되면 

사전에 정의된 파이프라인 코드에 따라 자동으로 각 단계를 수행해 효율적이고 빠르게 소스를 반영 및 테스트 하고 배포까지 할 수 있습니다. 

 