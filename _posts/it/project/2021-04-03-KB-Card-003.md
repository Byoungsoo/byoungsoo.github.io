---
layout: post
title: "Project - KBCard 성능테스트"
author: "Bys"
category: project
date: 2021-04-03 01:00:00
tags: project issue
---

#### **- 성능테스트**  

성능 테스트는 시간당 사용자수, 분당 사용자수, 초당 사용자수, 사용자당 트랜잭션 수 등을 통해 초당 트랜잭션 수를  계산한다.  
이 번 성능테스트의 목표 TPS는 2100 TPS로 목표 응답시간은 2초 이내 응답이다.  

테스트 시나리오는 3개의 시나리오로 진행한다.  
1. 목표 성능 테스트 - 복합 업무를 대상으로 산정된 목표 부하를 부여하였을 때, 성능 목표에 도달 하는지 여부를 확인  
대상업무: API 4개  //  부하발생: 5분간 Ramp Up  //  부하지속: 10분간 지속

![k01](/assets/it/project/kbcard/mydata/k01.png){: width="60%" height="auto"}  

2. 임계부하 성능 테스트 - 복합 업무를 대상으로 최대 부하를 부여하였을 때, 처리 가능한 최대 TPS 수준을 확인
대상업무: API 4개  //  부하발생: 1초당 1명씩 Ramp Up  //  부하지속: 최대 TPS 도달 시 종료  

![k02](/assets/it/project/kbcard/mydata/k02.png){: width="60%" height="auto"}  

3. 장시간 안정성 테스트 - 목표 부하 성능테스트를 장시간(최소6시간) 수행하여 시스템의 장시간 부하 영향을 확인  
대상업무: API 4개  //  부하지속: 6시간 ~ 24시간  

![k03](/assets/it/project/kbcard/mydata/k03.png){: width="60%" height="auto"}  

<br><br>

#### **- 성능테스트 - UBF 튜닝1**  

초기 4개의 Pod에서 부하를 시작하였을 때, 응답시간 지연이 쌓이기 시작하였다.  

![k04](/assets/it/project/kbcard/mydata/k04.png){: width="90%" height="auto"}  

Jennifer 상에서 증가하는 응답시간을 잡아보니 실제 SQL 수행시간이 오래걸렸고 해당 Query에 대한 튜닝을 진행하고 나서야 정상 응답시간으로 복구하였다.  

![k05](/assets/it/project/kbcard/mydata/k05.png){: width="90%" height="auto"}  

<br><br>



#### **- 성능테스트 - UBF 튜닝2**  

초기 4개의 Pod에서 부하를 시작하였을 때, Scale-Out이 되면서 갑자기 모든 Pod에 부하가 걸리면서 죽는 현상이 발생하였다.  
Scale-Out이 되었지만 Scale-Out 된 Pod로 아직은 부하가 들어오기 전이라는 시점이 이상하여 Scale-Out이 문제였는지, 아니면 다른게 이상했는지 판단하기가 어려웠다.  
그래서 다시 한 번 테스트 수행을 요청하였고, 이번에는 Scale-Out이 되기 전에 죽는현상이 있었다.  

따라서 기존 소스코드에 무엇이 문제였는지 파악이 시급했다.  
다시 한 번 Test를 돌리면서 죽을 때 쯔음 Thread Dump를 생성하기 시작했다.  

![k05](/assets/it/project/kbcard/mydata/k05.png){: width="90%" height="auto"}  

제니퍼 상에서는 DB Connection get failed 오류가 많이 발생하였고, ThreadDump를 보니 JDBC Getconnection을 waiting 하는 Thread들이 많이 있었다.  

정확한 이유는 모르겠지만 Main Thread에서 Nested transaction으로 별도 Thread를 생성하여 로그를 추가로 Insert 하는 로직이 있었는데 해당 로직을 빼고 수행해보니  
Pod이 죽지 않고 정상적으로 수행하는 것을 확인하였다.  

Http요청하나가 종료할 때 까지 DB Connection Pool하나를 사용한다고하여 (추가확인필요) 모든 Connection Pool이 Http 요청을 처리하는 중  
Nested Transaction 으로 분기된 Thread에서 Getconnection을 할 때 오류가 발생하나 싶어, Nested Transcation용 Connection Pool을 별도로 생성하였으며  
소스 상에서 로그 Insert하는 Nested Transaction은 해당 Connection Pool에서 Connection을 가져다가 사용하도록 소스 변경을 하였고 정상 처리되었다.  

조금 더 정확한 사유 확인이 필요한 케이스이다.  

```bash
at sun.misc.Unsafe.park(Native Method) 
at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215) 
at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedNanos(AbstractQueuedSynchronizer.java:1037) 
at java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1328) 
at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:277) 
at org.apache.tomcat.jdbc.pool.FairBlockingQueue.poll(FairBlockingQueue.java:153) 
at org.apache.tomcat.jdbc.pool.ConnectionPool.borrowConnection(ConnectionPool.java:686) 
at org.apache.tomcat.jdbc.pool.ConnectionPool.getConnection(ConnectionPool.java:198) 
at org.apache.tomcat.jdbc.pool.DataSourceProxy.getConnection(DataSourceProxy.java:132) 
at aries.runtime.tracer.JDBCConnectionTrace.getConnection(JDBCConnectionTrace.java:123) 
at aries.runtime.tracer.impl.ProfileSQLConnectionImpl.getConnection(ProfileSQLConnectionImpl.java:371) 
at aries.base.profile.ProfileSQL.getConnection(ProfileSQL.java:325) 
at aries.base.jdk.DataSource.getConnection(DataSource.java:76) 
at devonframework.persistent.connection.LJndiDataSource.getConnection(LJndiDataSource.java:130) 
at devonframework.persistent.connection.LDataSourcePool.getJNDIConnection(LDataSourcePool.java:342) 
at devonframework.persistent.connection.LDataSourcePool.getConnection(LDataSourcePool.java:137) 
at devonframework.persistent.dao.LConnectionManager.getConnection(LConnectionManager.java:86) 
at devonframework.business.transaction.LConnectionMapper.getConnection(LConnectionMapper.java:106) 
at devonframework.persistent.autodao.LAutoDao.getConnection(LAutoDao.java:239) 
at devonframework.persistent.autodao.LAutoDao.getConnection(LAutoDao.java:213) 
at devonframework.persistent.autodao.LCommonDao.executeQueryForSingle(LCommonDao.java:790) 
at devonframework.persistent.autodao.LCommonDao.executeQueryForSingle(LCommonDao.java:494) 
at devonenterprise.service.tranctrl.composite.CompositeTranCtrl.checkCompositeSvcCtrl(CompositeTranCtrl.java:86) 
at devonenterprise.ext.front.command.RestInboundCommand.execute(RestInboundCommand.java:307) 
at devonenterprise.ext.channel.interceptor.ExtCommandInterceptor.executeCommand(ExtCommandInterceptor.java:116) 
at devonenterprise.ext.channel.interceptor.ExtCommandInterceptor.execute(ExtCommandInterceptor.java:87) 
at devonenterprise.ext.channel.interceptor.ExtCommandInterceptor.doIntercept(ExtCommandInterceptor.java:45) 
at devonframework.front.channel.interceptor.LInterceptorChain.doIntercept(LInterceptorChain.java:93) 
at devonenterprise.ext.channel.interceptor.GuidCreateInterceptor.doIntercept(GuidCreateInterceptor.java:27) 
at devonframework.front.channel.interceptor.LInterceptorChain.doIntercept(LInterceptorChain.java:93) 
at devonframework.front.channel.interceptor.LConverterInterceptor.doIntercept(LConverterInterceptor.java:171) 
at devonframework.front.channel.interceptor.LInterceptorChain.doIntercept(LInterceptorChain.java:93) 
at devonframework.front.channel.LAbstractServlet.process(LAbstractServlet.java:290) 
at devonenterprise.ext.channel.adaptor.http.sync.impl.GeneralRestServlet.catchService(GeneralRestServlet.java:62) 
at devonframework.front.channel.LAbstractServlet.doCommon(LAbstractServlet.java:167) 
at devonframework.front.channel.LAbstractServlet.doPost(LAbstractServlet.java:106) 
at javax.servlet.http.HttpServlet.service(HttpServlet.java:652) 
at javax.servlet.http.HttpServlet.service(HttpServlet.java:733) 
at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) 
at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
```
<br><br>


#### **- 성능테스트 - UBF 튜닝3**  

위 의 이슈들이 해결되고, 정상적으로 부하를 받던 중 Scale-Out된 Pod이 정상적으로 Heatlh Check된 이 후 문제가 발생하였다.  
ALB Target에 등록되어 트래픽을 받을 때 응답시간의 지연이 발생하는 경우였다.  Jennifer 상에서는 

#### **- 성능테스트 - UBF 튜닝4**  

부하가 들어오기 시작 하고 나서부터 응답시간이 지속적으로 올라가기 시작했다.  

![k04](/assets/it/project/kbcard/mydata/k04.png){: width="90%" height="auto"}  

Jennifer 상에서 증가하는 응답시간을 잡아보니 실제 SQL 수행시간이 오래걸렸고 해당 Query에 대한 튜닝을 진행하고 나서야 정상 응답시간으로 복구하였다.  

![k05](/assets/it/project/kbcard/mydata/k05.png){: width="90%" height="auto"}  

<br><br>
